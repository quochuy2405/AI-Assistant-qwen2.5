# ğŸ¤– ZiZi AI - Trá»£ LÃ½ AI ThÃ´ng Minh

**ZiZi AI** lÃ  má»™t há»‡ thá»‘ng trá»£ lÃ½ AI thÃ´ng minh Ä‘Æ°á»£c phÃ¡t triá»ƒn vá»›i Qwen2.5, há»— trá»£ streaming chat vÃ  tÃ­ch há»£p knowledge base tá»« tÃ i liá»‡u text.

![ZiZi AI](https://img.shields.io/badge/ZiZi-AI-blue?style=for-the-badge)
![Python](https://img.shields.io/badge/Python-3.8+-green?style=for-the-badge)
![FastAPI](https://img.shields.io/badge/FastAPI-Latest-red?style=for-the-badge)
![Qwen2.5](https://img.shields.io/badge/Qwen2.5-7B-orange?style=for-the-badge)

## âœ¨ TÃ­nh NÄƒng ChÃ­nh

- ğŸ¤– **AI Assistant**: Sá»­ dá»¥ng Qwen2.5 qua Ollama
- ğŸ’¬ **Streaming Chat**: Tráº£ lá»i real-time vá»›i SSE
- ğŸ“š **Knowledge Base**: TÃ­ch há»£p tÃ i liá»‡u training tá»« txt files
- ğŸŒ **Web UI**: Giao diá»‡n chat hiá»‡n Ä‘áº¡i, thÃ¢n thiá»‡n
- ğŸ”Œ **REST API**: OpenAI-compatible endpoints
- ğŸ‡»ğŸ‡³ **Tiáº¿ng Viá»‡t**: Há»— trá»£ hoÃ n toÃ n tiáº¿ng Viá»‡t

## ğŸš€ CÃ i Äáº·t Nhanh

### 1. YÃªu Cáº§u Há»‡ Thá»‘ng
```bash
# Python 3.8+
python --version

# Ollama (Ä‘á»ƒ cháº¡y Qwen2.5)
# Táº£i táº¡i: https://ollama.ai
```

### 2. Setup Project
```bash
# Clone repository
git clone <repository-url>
cd AI-Support

# CÃ i Ä‘áº·t dependencies
pip install -r requirements_api.txt

# CÃ i Ä‘áº·t Ollama model
ollama pull qwen2.5:7b
```

### 3. Load Training Data
```bash
# Load tÃ i liá»‡u Zizi vÃ o knowledge base
python load_zizi_training.py
```

### 4. Khá»Ÿi Cháº¡y Há»‡ Thá»‘ng

#### Option 1: Full Stack (API + Frontend)
```bash
python run_zizi_ai.py
```

#### Option 2: Cháº¡y RiÃªng Láº»
```bash
# Terminal 1: API Server
python start_api_server.py

# Terminal 2: Frontend Server  
python start_frontend.py
```

## ğŸŒ Truy Cáº­p

- **Frontend UI**: http://localhost:8501
- **API Server**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs

## ğŸ“ Cáº¥u TrÃºc Project

```
ZiZi-AI/
â”œâ”€â”€ ğŸ¤– api/                          # API Backend
â”‚   â”œâ”€â”€ models.py                    # Data models
â”‚   â”œâ”€â”€ responses.py                 # AI response logic
â”‚   â”œâ”€â”€ config.py                    # Configuration
â”‚   â””â”€â”€ utils.py                     # Utilities
â”œâ”€â”€ ğŸŒ frontend/                     # Web Frontend
â”‚   â”œâ”€â”€ index.html                   # Main chat UI
â”‚   â”œâ”€â”€ chat.js                      # Chat functionality
â”‚   â””â”€â”€ style.css                    # Modern UI styles
â”œâ”€â”€ ğŸ“š knowledge_base.py             # Knowledge base management
â”œâ”€â”€ ğŸ“„ huong-dan-su-dung-zizi-project-day-du.txt  # Training data
â”œâ”€â”€ ğŸš€ start_api_server.py           # API launcher
â”œâ”€â”€ ğŸŒ start_frontend.py             # Frontend launcher
â”œâ”€â”€ ğŸ“– load_zizi_training.py         # Training script
â””â”€â”€ ğŸƒ run_zizi_ai.py               # Full stack launcher
```

## ğŸ”Œ API Endpoints

### Chat Completions
```bash
POST /chat/completions
Content-Type: application/json

{
  "messages": [
    {"role": "user", "content": "ZiZi project lÃ  gÃ¬?"}
  ],
  "stream": true
}
```

### Health Check
```bash
GET /health
```

### Models List
```bash
GET /models
```

### Statistics
```bash
GET /stats
```

## ğŸ’¬ CÃ¡ch Sá»­ Dá»¥ng

### 1. Chat vá»›i ZiZi AI
- Má»Ÿ http://localhost:8501
- Nháº­p cÃ¢u há»i vá» Zizi Project
- Nháº­n pháº£n há»“i thÃ´ng minh vá»›i knowledge base

### 2. API Integration
```python
import requests

response = requests.post("http://localhost:8000/chat/completions", 
    json={
        "messages": [{"role": "user", "content": "HÆ°á»›ng dáº«n cÃ i Ä‘áº·t Zizi?"}],
        "stream": False
    })

print(response.json())
```

### 3. Streaming Chat
```javascript
const eventSource = new EventSource('/chat/completions?stream=true');
eventSource.onmessage = function(event) {
    const data = JSON.parse(event.data);
    console.log(data.choices[0].delta.content);
};
```

## ğŸ› ï¸ Configuration

### API Settings (api/config.py)
```python
# Ollama settings
OLLAMA_BASE_URL = "http://localhost:11434"
OLLAMA_MODEL = "qwen2.5:7b"

# API settings  
API_HOST = "0.0.0.0"
API_PORT = 8000
```

### Frontend Settings (start_frontend.py)
```python
# Frontend server
FRONTEND_PORT = 8501
```

## ğŸ“š Knowledge Base

ZiZi AI sá»­ dá»¥ng ChromaDB Ä‘á»ƒ lÆ°u trá»¯ vÃ  tÃ¬m kiáº¿m knowledge base:

- **Embedding**: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
- **Vector Store**: ChromaDB
- **Chunking**: 1000 characters vá»›i overlap 200

### ThÃªm TÃ i Liá»‡u Má»›i
```python
from knowledge_base import KnowledgeBase

kb = KnowledgeBase()
kb.load_txt("new_document.txt")
```

## ğŸ”§ Troubleshooting

### Lá»—i Ollama Connection
```bash
# Kiá»ƒm tra Ollama running
ollama list

# Restart Ollama
ollama serve
```

### Lá»—i Knowledge Base
```bash
# Reset knowledge base
rm -rf chroma_db/
python load_zizi_training.py
```

### Lá»—i Port Conflicts
```bash
# Kiá»ƒm tra port sá»­ dá»¥ng
lsof -i :8000
lsof -i :8501

# Kill process
kill -9 <PID>
```

## ğŸ¤ Contributing

1. Fork project
2. Táº¡o feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Má»Ÿ Pull Request

## ğŸ“„ License

Distributed under the MIT License. See `LICENSE` for more information.

## ğŸ“ Contact

**ZiZi AI Team**
- ğŸ“§ Email: support@zizi-ai.com
- ğŸŒ Website: https://zizi-ai.com
- ğŸ“± Discord: ZiZi AI Community

## ğŸ™ Acknowledgments

- [Qwen2.5](https://github.com/QwenLM/Qwen2.5) - Powerful LLM
- [Ollama](https://ollama.ai) - Local LLM runtime
- [FastAPI](https://fastapi.tiangolo.com) - Modern API framework
- [ChromaDB](https://www.trychroma.com) - Vector database
- [Streamlit](https://streamlit.io) - Web UI framework

---

<div align="center">
  <strong>ğŸ¤– ZiZi AI - Trá»£ LÃ½ AI ThÃ´ng Minh Cho Má»i NgÆ°á»i ğŸ‡»ğŸ‡³</strong>
</div> 