# ğŸš€ HÆ¯á»šNG DáºªN SETUP NHANH - AI Há»– TRá»¢ KOC

## âš¡ Setup 1 dÃ²ng lá»‡nh (KhuyÃªn dÃ¹ng)

```bash
chmod +x setup.sh && ./setup.sh
```

## ğŸ“‹ Setup thá»§ cÃ´ng (Tá»«ng bÆ°á»›c)

### 1ï¸âƒ£ CÃ i Ä‘áº·t Ollama

**macOS:**
```bash
brew install ollama
brew services start ollama
```

**Linux:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
ollama serve &
```

**Windows:** Táº£i tá»« https://ollama.com/download/windows

### 2ï¸âƒ£ Táº£i model LLAMA

```bash
ollama pull llama2
```

### 3ï¸âƒ£ CÃ i Python packages

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Cháº¡y app

```bash
python run_app.py
```

## ğŸŒ Truy cáº­p

Má»Ÿ trÃ¬nh duyá»‡t: **http://localhost:8501**

## âœ… Kiá»ƒm tra cÃ i Ä‘áº·t

```bash
# Kiá»ƒm tra Ollama
ollama list

# Kiá»ƒm tra Python packages
python -c "import streamlit, ollama; print('âœ… OK')"

# Test app
python run_app.py
```

## ğŸ› Xá»­ lÃ½ lá»—i nhanh

### Lá»—i: "Cannot connect to Ollama"
```bash
ollama serve &
sleep 5
ollama pull llama2
```

### Lá»—i: "Module not found"
```bash
pip install -r requirements.txt --force-reinstall
```

### Lá»—i: "Model not found"
```bash
ollama list
ollama pull llama2
```

## ğŸ“ Cáº¥u trÃºc files quan trá»ng

```
AI-Support/
â”œâ”€â”€ app.py              # App chÃ­nh
â”œâ”€â”€ requirements.txt    # Dependencies
â”œâ”€â”€ setup.sh           # Script setup tá»± Ä‘á»™ng
â”œâ”€â”€ run_app.py         # Launcher vá»›i check
â””â”€â”€ README_SETUP.md    # HÆ°á»›ng dáº«n nÃ y
```

## ğŸ¯ Sá»­ dá»¥ng app

1. **Upload PDF** â†’ Tab "Táº£i TÃ i Liá»‡u"
2. **Chat AI** â†’ Tab "TrÃ² Chuyá»‡n"  
3. **Xem stats** â†’ Tab "Thá»‘ng KÃª"

## ğŸ“ Há»— trá»£

- **GitHub Issues:** Táº¡o issue má»›i
- **Email:** Gá»­i kÃ¨m log lá»—i
- **Docs:** Xem README.md Ä‘áº§y Ä‘á»§

---
â­ **ChÃºc báº¡n setup thÃ nh cÃ´ng!** â­ 