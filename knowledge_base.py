import chromadb
import json
import os
from typing import List, Dict, Optional
from sentence_transformers import SentenceTransformer
import numpy as np
from datetime import datetime
from pdf_processor import PDFProcessor

class KnowledgeBase:
    """Qu·∫£n l√Ω knowledge base cho AI Assistant"""
    
    def __init__(self, persist_directory: str = "./chroma_db"):
        self.persist_directory = persist_directory
        self.client = chromadb.PersistentClient(path=persist_directory)
        
        # Kh·ªüi t·∫°o embedding model
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # Kh·ªüi t·∫°o PDF processor
        self.pdf_processor = PDFProcessor()
        
        # T·∫°o ho·∫∑c l·∫•y collection
        collection_name = "app_guide_knowledge"
        try:
            # Th·ª≠ l·∫•y collection c√≥ s·∫µn
            self.collection = self.client.get_collection(collection_name)
        except Exception as e:
            try:
                # N·∫øu kh√¥ng t·ªìn t·∫°i, t·∫°o m·ªõi
                self.collection = self.client.create_collection(
                    name=collection_name,
                    metadata={"description": "Knowledge base for app guidance"}
                )
            except Exception as create_error:
                # N·∫øu t·∫°o m·ªõi th·∫•t b·∫°i, th·ª≠ get_or_create
                try:
                    self.collection = self.client.get_or_create_collection(
                        name=collection_name,
                        metadata={"description": "Knowledge base for app guidance"}
                    )
                except Exception as final_error:
                    print(f"L·ªói kh·ªüi t·∫°o collection: {final_error}")
                    raise final_error
        
        # File ƒë·ªÉ l∆∞u metadata
        self.metadata_file = os.path.join(persist_directory, "metadata.json")
        self.load_metadata()
    
    def load_pdf(self, pdf_path: str) -> bool:
        """
        Load PDF file v√†o knowledge base
        
        Args:
            pdf_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file PDF
            
        Returns:
            True n·∫øu th√†nh c√¥ng, False n·∫øu th·∫•t b·∫°i
        """
        try:
            if not os.path.exists(pdf_path):
                print(f"‚ùå File kh√¥ng t·ªìn t·∫°i: {pdf_path}")
                return False
            
            # Extract v√† chunk PDF
            print(f"üìÑ Processing PDF: {pdf_path}")
            text_chunks = self.pdf_processor.extract_and_chunk_pdf(pdf_path)
            
            # L·∫•y t√™n file l√†m document name
            document_name = os.path.basename(pdf_path).replace('.pdf', '')
            
            # Th√™m v√†o knowledge base
            self.add_documents(text_chunks, document_name)
            
            print(f"‚úÖ Successfully loaded {len(text_chunks)} chunks from {pdf_path}")
            return True
            
        except Exception as e:
            print(f"‚ùå Error loading PDF {pdf_path}: {e}")
            return False
    
    def load_metadata(self):
        """T·∫£i metadata t·ª´ file"""
        try:
            if os.path.exists(self.metadata_file):
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    self.metadata = json.load(f)
            else:
                self.metadata = {
                    'documents': [],
                    'total_chunks': 0,
                    'last_updated': None
                }
        except Exception:
            self.metadata = {
                'documents': [],
                'total_chunks': 0,
                'last_updated': None
            }
    
    def save_metadata(self):
        """L∆∞u metadata v√†o file"""
        try:
            os.makedirs(self.persist_directory, exist_ok=True)
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(self.metadata, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"L·ªói l∆∞u metadata: {e}")
    
    def add_documents(self, text_chunks: List[Dict[str, str]], document_name: str):
        """
        Th√™m t√†i li·ªáu v√†o knowledge base
        
        Args:
            text_chunks: List c√°c text chunks
            document_name: T√™n t√†i li·ªáu
        """
        if not text_chunks:
            return
        
        # T·∫°o embeddings cho t·∫•t c·∫£ chunks
        texts = [chunk['content'] for chunk in text_chunks]
        embeddings = self.embedding_model.encode(texts)
        
        # Chu·∫©n b·ªã d·ªØ li·ªáu cho ChromaDB
        ids = []
        metadatas = []
        documents = []
        
        for i, chunk in enumerate(text_chunks):
            chunk_id = f"{document_name}_{chunk['id']}"
            ids.append(chunk_id)
            documents.append(chunk['content'])
            metadatas.append({
                'document_name': document_name,
                'chunk_id': chunk['id'],
                'length': chunk['length'],
                'timestamp': datetime.now().isoformat()
            })
        
        # Th√™m v√†o collection
        self.collection.add(
            ids=ids,
            embeddings=embeddings.tolist(),
            documents=documents,
            metadatas=metadatas
        )
        
        # C·∫≠p nh·∫≠t metadata
        if document_name not in self.metadata['documents']:
            self.metadata['documents'].append(document_name)
        
        self.metadata['total_chunks'] += len(text_chunks)
        self.metadata['last_updated'] = datetime.now().isoformat()
        
        self.save_metadata()
        
        print(f"ƒê√£ th√™m {len(text_chunks)} chunks t·ª´ {document_name}")
    
    def search(self, query: str, k: int = 5) -> List[Dict[str, any]]:
        """
        T√¨m ki·∫øm th√¥ng tin li√™n quan ƒë·∫øn c√¢u h·ªèi
        
        Args:
            query: C√¢u h·ªèi t√¨m ki·∫øm
            k: S·ªë l∆∞·ª£ng k·∫øt qu·∫£ tr·∫£ v·ªÅ
            
        Returns:
            List c√°c document li√™n quan
        """
        if self.collection.count() == 0:
            return []
        
        try:
            # T·∫°o embedding cho query
            query_embedding = self.embedding_model.encode([query])
            
            # T√¨m ki·∫øm
            results = self.collection.query(
                query_embeddings=query_embedding.tolist(),
                n_results=min(k, self.collection.count())
            )
            
            # X·ª≠ l√Ω k·∫øt qu·∫£
            search_results = []
            
            if results['documents'] and results['documents'][0]:
                for i in range(len(results['documents'][0])):
                    result = {
                        'content': results['documents'][0][i],
                        'metadata': results['metadatas'][0][i],
                        'distance': results['distances'][0][i] if 'distances' in results else 0,
                        'id': results['ids'][0][i]
                    }
                    search_results.append(result)
            
            return search_results
            
        except Exception as e:
            print(f"L·ªói t√¨m ki·∫øm: {e}")
            return []
    
    def search_by_document(self, document_name: str, query: str = None, k: int = 10) -> List[Dict[str, any]]:
        """
        T√¨m ki·∫øm trong m·ªôt t√†i li·ªáu c·ª• th·ªÉ
        
        Args:
            document_name: T√™n t√†i li·ªáu
            query: C√¢u h·ªèi (optional)
            k: S·ªë l∆∞·ª£ng k·∫øt qu·∫£
            
        Returns:
            List c√°c chunk t·ª´ t√†i li·ªáu ƒë√≥
        """
        try:
            if query:
                # T√¨m ki·∫øm theo query trong document
                query_embedding = self.embedding_model.encode([query])
                
                results = self.collection.query(
                    query_embeddings=query_embedding.tolist(),
                    n_results=k,
                    where={"document_name": document_name}
                )
            else:
                # L·∫•y t·∫•t c·∫£ chunk t·ª´ document
                results = self.collection.get(
                    where={"document_name": document_name},
                    limit=k
                )
            
            # X·ª≠ l√Ω k·∫øt qu·∫£
            search_results = []
            
            if results['documents']:
                documents = results['documents'][0] if isinstance(results['documents'][0], list) else results['documents']
                metadatas = results['metadatas'][0] if isinstance(results['metadatas'][0], list) else results['metadatas']
                ids = results['ids'][0] if isinstance(results['ids'][0], list) else results['ids']
                
                for i in range(len(documents)):
                    result = {
                        'content': documents[i],
                        'metadata': metadatas[i],
                        'id': ids[i]
                    }
                    if 'distances' in results:
                        result['distance'] = results['distances'][0][i]
                    search_results.append(result)
            
            return search_results
            
        except Exception as e:
            print(f"L·ªói t√¨m ki·∫øm theo t√†i li·ªáu: {e}")
            return []
    
    def delete_document(self, document_name: str) -> bool:
        """
        X√≥a t√†i li·ªáu kh·ªèi knowledge base
        
        Args:
            document_name: T√™n t√†i li·ªáu c·∫ßn x√≥a
            
        Returns:
            True n·∫øu x√≥a th√†nh c√¥ng
        """
        try:
            # L·∫•y t·∫•t c·∫£ IDs c·ªßa document
            results = self.collection.get(
                where={"document_name": document_name}
            )
            
            if results['ids']:
                # X√≥a t·∫•t c·∫£ chunks c·ªßa document
                self.collection.delete(ids=results['ids'])
                
                # C·∫≠p nh·∫≠t metadata
                if document_name in self.metadata['documents']:
                    self.metadata['documents'].remove(document_name)
                
                self.metadata['total_chunks'] -= len(results['ids'])
                self.metadata['last_updated'] = datetime.now().isoformat()
                
                self.save_metadata()
                
                print(f"ƒê√£ x√≥a t√†i li·ªáu {document_name}")
                return True
            
            return False
            
        except Exception as e:
            print(f"L·ªói x√≥a t√†i li·ªáu: {e}")
            return False
    
    def get_statistics(self) -> Dict[str, any]:
        """L·∫•y th·ªëng k√™ v·ªÅ knowledge base"""
        try:
            collection_count = self.collection.count()
            
            return {
                'total_documents': len(self.metadata['documents']),
                'total_chunks': collection_count,
                'documents': self.metadata['documents'],
                'last_updated': self.metadata['last_updated'],
                'database_size': self._get_db_size()
            }
        except Exception:
            return {
                'total_documents': 0,
                'total_chunks': 0,
                'documents': [],
                'last_updated': None,
                'database_size': 0
            }
    
    def _get_db_size(self) -> float:
        """T√≠nh k√≠ch th∆∞·ªõc database (MB)"""
        try:
            total_size = 0
            for dirpath, dirnames, filenames in os.walk(self.persist_directory):
                for filename in filenames:
                    filepath = os.path.join(dirpath, filename)
                    total_size += os.path.getsize(filepath)
            return round(total_size / (1024 * 1024), 2)  # Convert to MB
        except Exception:
            return 0
    
    def clear_all(self) -> bool:
        """X√≥a to√†n b·ªô knowledge base"""
        try:
            # X√≥a collection
            self.client.delete_collection("app_guide_knowledge")
            
            # T·∫°o l·∫°i collection m·ªõi
            self.collection = self.client.create_collection(
                name="app_guide_knowledge",
                metadata={"description": "Knowledge base for app guidance"}
            )
            
            # Reset metadata
            self.metadata = {
                'documents': [],
                'total_chunks': 0,
                'last_updated': None
            }
            self.save_metadata()
            
            print("ƒê√£ x√≥a to√†n b·ªô knowledge base")
            return True
            
        except Exception as e:
            print(f"L·ªói x√≥a knowledge base: {e}")
            return False
    
    def get_document_list(self) -> List[str]:
        """L·∫•y danh s√°ch t√†i li·ªáu"""
        return self.metadata['documents'].copy()
    
    def is_empty(self) -> bool:
        """Ki·ªÉm tra knowledge base c√≥ tr·ªëng kh√¥ng"""
        return self.collection.count() == 0 